{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Projects\"\noutput: html_document\n---\n\nThis project was completed as a part of the udacity data science with R nano degree program. The project goal was to formulate and answer some questions using the bikeshare data from three US cities.\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(data.table)\nlibrary(stringr)\nlibrary(ggplot2)\n\n\n#plot background theme, chosen by my 6 yr old :)\nth1<- theme(\n              panel.background = element_rect(fill = \"pink\",\n                                colour = \"pink\",\n                                size = 0.5, linetype = \"solid\"),\n              panel.grid.major = element_line(size = 0.5, linetype = 'solid',\n                                colour = \"white\"), \n              panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                colour = \"white\"))\n# color palette vector for line plots\nc.palette <- c(\"purple\", \"magenta\", \"turquoise\")\n```\n\n# Question 1: Popular times of travel \nWhat is the most common month ?\nWhat is the most common day of week?\nWhat is the most common hour of day?\n\n##Step a) Data Cleaning and organization - \nIn the first R code chunk, I used data.table library to read only the columns of interest, and to create a new column 'City' (fill it with values Chicago, Newyork and Washington respectively) for all three data sets. I then combined all of the data tables into one using rbind. Finally, I used the stringr replace all function for replacing the spaces in column names with a dot. This wrangling work resulted in creating one table for creating all of the summaries and visualizations needed to answer this question. \n\n```{R}\nch <- fread(\"Data/chicago.csv\", select = c(2,3,4))         # read csv as data table\nch[,\"City\":=\"Chicago\"]\n\nny <- fread('Data/new-york-city.csv', select = c(2,3,4))\nny[,\"City\":= \"Newyork\"]\n\nwa <- fread('Data/washington.csv', select = c(2,3,4))\nwa[,\"City\":= \"Washington\"]\n\ndt <- rbind(ch,ny,wa)                                 #combine data tables\nnames(dt) <- str_replace_all(names(dt), c(\" \"=\".\"))   #replace empty space in column name with a .\nstrt <- as.POSIXct(dt$Start.Time)                     #POSIX for timestamps as calendar times\ndt[, \"start.month\" := strftime(strt, \"%b\")]           #extracting month from timestamp and storing in a new column start.month\ndt[, \"start.DOW\" := strftime(strt, \"%a\")]             #extracting day of week from timestamp and storing in a new column start.DOW\ndt[, \"start.hourofday\" := strftime(strt, \"%H\")]       #extracting hour of day from timestamp and storing in a new column start.hourofday\nhead(dt)\n```\n\n##Step b) Functions for creating summaries\ni) Get.Most.Common --> returns the most common (i.e. the highest count) metric combined for the three cities (overall) as well as broken down per city (grouped)\n\n```{r}\nGet.Most.Common <- function(metric, grp.by){\n      usr_input1<- metric\n      usr_input2<- grp.by\n      txt_usr_input1<- deparse((substitute(metric)))    # only retaining the text of the argument\n      txt_usr_input2<-deparse((substitute(grp.by)))    # only retaining the text of the argument\n      temp.overall<- dt[, .N, by=.(metric)]             #create list of count by metric (i.e. month, DOW or hour) for the entrie table\n      overall <- temp.overall[, .SD[which.max(N)]]      # find the highest count i.e. the most common\n      setnames(overall, \"metric\",sub('...','',txt_usr_input1))        #output table headers to reflect input text\n      setnames(overall, \"N\", \"Overall_ Count\")\n      temp.bygrp <- dt[, .N, by=.(grp.by, metric)]      # create count grouped by city and the metric\n      bygrp <-temp.bygrp[, .SD[which.max(N)], by =grp.by]   #find max\n      setnames(bygrp, \"grp.by\",sub('...','',txt_usr_input2))              #rename headers\n      setnames(bygrp, \"metric\",sub('...','',txt_usr_input1))\n      setnames(bygrp, \"N\", \"Grouped_ Count\")\n      \n      result <- list(\"Most Common Overall\"=overall, \"Most Common Grouped\"= bygrp)   #combine outputs into a list since a function can only have       \n    \n     \n      return(result)\n     \n}\nprint(\"-----Most common Month-----\")\nGet.Most.Common(dt$start.month, dt$City)\nprint(\"-----Most common day of the week-----\")\nGet.Most.Common(dt$start.DOW, dt$City)\nprint(\"-----Most common hour of the day-----\")\nGet.Most.Common(dt$start.hourofday,dt$City)\n```\n\nii) Freq.Categorical - creates frequency tables for categorical variable input combined for the three cities (overall) as well as broken down per city (grouped). The frequency table supplements the data visualizations created using ggplot2, if viewers need to take a look at exact numbers for a certain metric.\n\n```{r}\n\n#function to calculate frequency tables and plots by metric \n#1-deparse will get text out of user input - for creating dynamic plot labels\n#2-Overall frequency followed by bygrp(by city) frequency table using data.table functions\n#3 - c.palette specifies color palette for the bygrp(by city) plots. \n#4-  create a list of ggplot items that are common to all plots.\n#5 -Conditional (if else) to order by monthor by day - do this forboth overall and bygrp(by city)plots.\nfreq.categorical <- function(metric, grp.by){  \n      \n      txt_usr_input1<- sub('...','',deparse((substitute(metric)))) #1\n      txt_usr_input2<- sub('...','',deparse((substitute(grp.by))))\n      temp.overall<- dt[, .N, by=.(metric)]#summarizing data\n      overall <- temp.overall[order(-N)]                #2\n      temp.bygrp <- dt[, .N, by=.(grp.by, metric)]\n      bygrp <- temp.bygrp[order(dt, -N)] #2\n      c.palette <- c(\"purple\", \"magenta\", \"turquoise\")#3\n      #4 (for overall)\n      p<- list(\n          geom_bar(stat = \"identity\", fill = \"purple\"), \n          ggtitle(paste0('Histogram for ', txt_usr_input1)),\n          scale_y_continuous(labels = function(x) format(x, scientific = FALSE)),\n          th1,labs(x = paste0(txt_usr_input1), y = 'Count')\n      )\n      #4 (for bygrp)\n      p2 <- list(geom_line(size = 1) ,\n                scale_y_continuous(labels = function(x) format(x, scientific = FALSE)),\n                geom_point( size=4, shape=21,fill=\"grey\"),\n                scale_color_manual(values = c.palette), th1,\n                ggtitle(paste0('Trend chart for ', txt_usr_input1, ' by ', txt_usr_input2)),\n                labs(x = paste0(txt_usr_input1), y = 'Count')\n        )\n      # 5 conditional\n      #if DOW (string) in the argument, then factor the metric column with levels as ordered days of week with Sunday being first day\n      if(str_detect(txt_usr_input1, \"DOW\")) {  \n          overall$metric <- factor(overall$metric, \n                                  levels =c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"))\n          overall<- overall[order(overall$metric)]\n          bygrp$metric <- factor(bygrp$metric, \n                                  levels =c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"))\n          bygrp<- bygrp[order(bygrp$metric)]\n          pltx <- ggplot(data=overall, aes_string(x=names(overall)[1], y = names(overall)[2])) + p  \n          plt2x<-ggplot(data=bygrp, aes_string(x=names(bygrp)[2], y=names(bygrp)[3], group = names(bygrp)[1], colour = names(bygrp)[1])) +p2\n      print(pltx)\n      print(plt2x)\n      #elseif month(string) in the argument, then use the month.abb function to order month JAn - DEc\n      }else if(str_detect(txt_usr_input1, \"month\")){\n          pltx <-ggplot(data=overall, aes_string(x=names(overall)[1], y = names(overall)[2])) +\n                 scale_x_discrete(limits = month.abb) + p\n          plt2x<-ggplot(data=bygrp, aes_string(x=names(bygrp)[2], y=names(bygrp)[3], group = names(bygrp)[1], colour = names(bygrp)[1])) +\n                 scale_x_discrete(limits = month.abb) + p2\n      print(pltx)\n      print(plt2x)\n      # else plot and print\n      }else{\n          pltx <- ggplot(data=overall, aes_string(x=names(overall)[1], y = names(overall)[2])) + p\n          plt2x<-ggplot(data=bygrp, aes_string(x=names(bygrp)[2], y=names(bygrp)[3], group = names(bygrp)[1], colour = names(bygrp)[1])) +p2\n      print(pltx)\n      print(plt2x)\n      }\n    \n      result <- list(\"Overall\"=overall, \"Grouped\"= bygrp) #combining summary result\n      \nreturn(result)\n     \n}\n\nfreq.categorical(dt$start.month, dt$City)\nfreq.categorical(dt$start.DOW, dt$City)\nfreq.categorical(dt$start.hourofday, dt$City)\n```\n##Step c) Results summary\nJune is the most common rental month overall, as well as for each of the cities. This may be driven by warm summer temperatures, tourists visitings due to school holidays etc.\nWednesday is the most common day for start of the rentals overall. When broken down by the city, we see that wednesday is still the most comon rental start day for New York and washington, but for Chicgo the most common day of retnal start is Tuesday. weekday rentals may be higher due to workers commuting to work.\nHourly data shows a bimodal distribution overall with 08:00am and 5:00pm being the most popular times for travel. This, again is likely due to the workers commuting to and from work at these hours. Trend by city shows the same dual peaks. The 5:00pm peak for washington is small, which may be due to overnight rentals. \n\n#Question 2: Trip duration\n\nWhat is the total travel time for users in different cities?\nWhat is the average travel time for users in different cities?\n\n##Step a) \nI used the same data table (dt) created in question 1 step a. The below code generates a summary table, a plot for total travel time by city and a plot for average travel time by city in minutes.\nNote: I could have used the available trip.duration column for this analysis, instead of calculating the duration (start time - end time). This helped me learn more, and output is in minutes opposed to Trip.Duration column which shows the time recorded in seconds. \n\n\n```{r}\n\nt1 <- strptime(dt$Start.Time, \"%Y-%m-%d %H:%M:%OS\") # t1 is date time object containig start time\nt2<- strptime(dt$End.Time, \"%Y-%m-%d %H:%M:%OS\")   #t2 is date time object containing end time\ndt[, \"Duration\" := as.numeric(t2-t1)]   # creating a new column 'duration' which is difference between start and end times in mins\nsummary.trip.duration <- dt [, .(Avg.time.min = mean(Duration), #generating summary table by city\n                              total.time.min = sum(Duration),\n                             Count = .N), \n                             by=City\n                            ][ order(-total.time.min) ]\nprint(summary.trip.duration)\n\nlibrary(ggplot2)                   \nplt3<- ggplot(data = summary.trip.duration, aes(x=City, y=total.time.min)) + #generating plot for total time\n        geom_bar(stat = \"identity\", fill = \"purple\")+\n          ggtitle(paste0('Histogram for total tavel time'))+\n          scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+\n          th1+labs(y = 'total travel time in minutes')\nprint(plt3)\n\nplt4 <- ggplot(data = summary.trip.duration, aes(x=City, y=Avg.time.min)) + #generating plot for average time\n        geom_bar(stat = \"identity\", fill = \"purple\")+\n          ggtitle(paste0('Histogram for average tavel time in minutes'))+\n          scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+\n          th1+labs(y = 'Average travel time in minutes')\nprint(plt4)\n\n```\n\n##Step b) Summary: \nAverage travel time is shortest for Washington at 12.41 min and longest for Chicago at 15.60 min. Total travel time is highest for chicago at > 4.6 million minutes, closely folowed by NY at ~4.5 million minutes. Washington shows lowest system utilization for all three cities at ~3.7million minutes usage for the 6 month period. \n\n#Question 3: User info\n\nWhat are the counts of each user type?\nWhat are the counts of each gender (only available for NYC and Chicago)?\nWhat are the earliest, most recent, most common year of birth (only available for NYC and Chicago)?\n\n##Step a) \nCounts for each user type, counts for each gender overall, and counts for each gender broken down by city. Again used the data.table library functions for creating summaries and ggplot for visualizations.\n```{r}\nch2 <- fread('Data/chicago.csv', select=c(7,8,9))\nch2[,\"City\":= \"Chicago\"]\n\nny2 <- fread('Data/new-york-city.csv', select = c(7,8,9))\nny2[,\"City\":= \"Newyork\"]\n\nwa2 <- fread('Data/washington.csv', select = c(7))\nwa2[,\"City\":= \"Washington\"]\n\ndt2<- rbind(ch2,ny2,wa2, fill = TRUE)  \nnames(dt2) <- str_replace_all(names(dt2), c(\" \"=\".\"))   #replace empty space in column name with a .\n\ncount.user.type <- dt2[User.Type !=\"\"][,.(Count = .N), by =User.Type][order(-Count)]\nprint(\"-------Counts of each user type---------\")\nprint(count.user.type)\n\ngs <- dt2[Gender!=\"\"& !is.na(Gender)][,.(Count=.N), by=Gender]\ngs.bycity<- dt2[Gender!=\"\"& !is.na(Gender)][,.(Count=.N), by=.(Gender,City)]\nprint(\"-------counts of each gender---------\")\nprint(gs)\nprint(\"-------counts of each gender by city---------\")\nprint(gs.bycity)\n\nplt5 <-ggplot(data=gs.bycity, aes(x = Gender, y= Count, fill = City)) +\n              geom_bar(stat=\"identity\", width=.5, position = \"dodge\")+\n              scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+\n              th1+ scale_fill_manual(values = c.palette)+\n              ggtitle('Histogram for gender count by city')+\n              labs(x = 'Gender', y = 'Count')\n  print(plt5)\n \n\n```\n\n##Summary:\nThe most common user type is subscriber. More male users overall than female. When looking at comparison by city, both cities individually have more male users.\n\n##Step b)\nEarliest, most recent and most common year of birth calculation: \n```{r}\n#order data table by birth year ascending - get most recent year\nr.yr <- dt2[Birth.Year!=\"\"& !is.na(Birth.Year)][,(max(Birth.Year))]\nprint(paste0(\"The most recent birth year is \",r.yr))\n#order data table by birth year descending - get earliest year\ne.yr <- dt2[Birth.Year!=\"\"& !is.na(Birth.Year)][,(min(Birth.Year))]\nprint(paste0(\"The earliest birth year is \",e.yr))\n#count number of occurences of each birht year, and order by count descending to get the most common year on top.\nc.yr <- dt2[Birth.Year!=\"\"& !is.na(Birth.Year)][,.(Count=.N), by=Birth.Year][order(-Count)]\nhead(c.yr,3)\n\nplt6 <-ggplot(data=c.yr, aes(x = Birth.Year, y= Count)) +\n              geom_bar(stat=\"identity\", fill = 'purple')+\n              scale_x_continuous(limits = c(1939, 2019), breaks = seq(1939, 2019, 10))+\n              scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+\n              th1+\n              ggtitle('Histogram for user count by birth year')+\n              labs(x = 'Birth Year', y = 'Count')\n  print(plt6)\n\n```\n\n##Summary:\nThe most recent birth year for users is 2016, the earliest birth year is 1885 (which may indicate that some users use the default option) and most common year is 1989. \n\nThats it. Thanks for reading!\n\n",
    "created" : 1597818096517.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "815782428",
    "id" : "F226DDE7",
    "lastKnownWriteTime" : 1597819448,
    "last_content_update" : 1597819448636,
    "path" : "~/Rwebsite/first_website/projects.Rmd",
    "project_path" : "projects.Rmd",
    "properties" : {
        "last_setup_crc32" : "48B00531b4091c42"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}